{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"!conda install -y gdown","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n!pip install python-terrier -q\n!pip install --upgrade git+https://github.com/terrierteam/pyterrier_t5.git -q\n!pip install -U sentence-transformers -q\n!pip install --upgrade gensim\n\nfrom sentence_transformers.util import cos_sim\n\nfrom scipy import stats\nfrom scipy.spatial import distance\nfrom scipy.spatial.distance import cosine\n\nimport pickle\nimport random\nimport pyterrier as pt\nimport pandas as pd\nimport numpy as np\nimport torch\nimport json\nimport os\nimport re\nimport math\nimport nltk\nnltk.download('punkt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!gdown 1cfgOF6kP8brxI_dtMTwhMEBGwgWBHjjV # nostops_queries_23-03-2024","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!gdown 1qKm6yxQ2KzSiGkNaJSYgxV4nC_MGPUka # nostops_data_23-03-2024","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"queries = pd.read_pickle(\"nostops_queries_23-03-24.pickle\")\nqueries = queries.rename(columns = {\"query\": \"query_raw\", \"query_preprocessed\": \"query\"})\nqueries.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_pickle(\"nostops_data_23-03-24.pickle\")\ndata = data.rename(columns = {\"keluhan\": \"keluhan_raw\", \"keluhan_preprocessed\": \"keluhan\"})\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nrandom.seed(42)\nnp.random.seed(42)\ntorch.manual_seed(42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sentence Transformer","metadata":{}},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nsentence_transformer = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n\npminilm_doc = dict()\nfor index, line in data.iterrows():\n    docno = line['docno']\n    pminilm_doc[docno] = sentence_transformer.encode(line['keluhan_raw'])\n\npminilm_query = dict()\nfor index, line in queries.iterrows():\n    qid = line['qid']\n    pminilm_query[qid] = sentence_transformer.encode(line['query_raw'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# T5 Encoder Model","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, T5EncoderModel\nt5_tokenizer = AutoTokenizer.from_pretrained(\"castorini/doc2query-t5-base-msmarco\")\nt5_model = T5EncoderModel.from_pretrained(\"castorini/doc2query-t5-base-msmarco\").to(device)\n\nt5_doc = dict()\nfor index, line in data.iterrows():\n    docno = line['docno']\n    input_ids = t5_tokenizer(\n        line['keluhan_raw'], return_tensors='pt', truncation=True, max_length=512\n    ).input_ids.to(device)\n    with torch.no_grad():\n        outputs = t5_model(input_ids=input_ids)\n        last_hidden_states = outputs.last_hidden_state\n    t5_doc[docno] = torch.mean(last_hidden_states, dim=1).detach().cpu().numpy().flatten()\n     \nt5_query = dict()\nfor index, line in queries.iterrows():\n    qid = line['qid']\n    input_ids = t5_tokenizer(\n        line['query_raw'], return_tensors='pt', truncation=True, max_length=512\n    ).input_ids.to(device)\n    with torch.no_grad():\n        outputs = t5_model(input_ids=input_ids)\n        last_hidden_states = outputs.last_hidden_state\n    t5_query[qid] = torch.mean(last_hidden_states, dim=1).detach().cpu().numpy().flatten()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pretrained IndoBERT","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, BertModel\nbert_tokenizer = AutoTokenizer.from_pretrained(\"stevenwh/indobert-base-p2-finetuned-mer-80k\")\nbert_model = BertModel.from_pretrained(\"stevenwh/indobert-base-p2-finetuned-mer-80k\").to(device)\n\nbert_doc = dict()\nfor index, line in data.iterrows():\n    docno = line['docno']\n    inputs = bert_tokenizer(\n        f\"[CLS] {line['keluhan_raw']} [SEP]\", return_tensors='pt', truncation=True, max_length=512\n    ).to(device)\n    with torch.no_grad():\n        outputs = bert_model(**inputs)\n    bert_doc[docno] = outputs.pooler_output[0].detach().cpu().numpy().flatten()\n    \nbert_query = dict()\nfor index, line in queries.iterrows():\n    qid = line['qid']\n    inputs = bert_tokenizer(\n        f\"[CLS] {line['query_raw']} [SEP]\", return_tensors='pt', truncation=True, max_length=512\n    ).to(device)\n    with torch.no_grad():\n        outputs = bert_model(**inputs)\n    bert_query[qid] = outputs.pooler_output[0].detach().cpu().numpy().flatten()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Export","metadata":{}},{"cell_type":"code","source":"with open('pminilm_query_26-03-24.pickle', 'wb') as handle:\n    pickle.dump(pminilm_query, handle, protocol=pickle.HIGHEST_PROTOCOL)\nwith open('pminilm_data_26-03-24.pickle', 'wb') as handle:\n    pickle.dump(pminilm_doc, handle, protocol=pickle.HIGHEST_PROTOCOL)\nwith open('t5_query_26-03-24.pickle', 'wb') as handle:\n    pickle.dump(t5_query, handle, protocol=pickle.HIGHEST_PROTOCOL)\nwith open('t5_data_26-03-24.pickle', 'wb') as handle:\n    pickle.dump(t5_doc, handle, protocol=pickle.HIGHEST_PROTOCOL)\nwith open('bert_query_26-03-24.pickle', 'wb') as handle:\n    pickle.dump(bert_query, handle, protocol=pickle.HIGHEST_PROTOCOL)\nwith open('bert_data_26-03-24.pickle', 'wb') as handle:\n    pickle.dump(bert_doc, handle, protocol=pickle.HIGHEST_PROTOCOL)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}